# -*- coding: utf-8 -*-
"""index_pred.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17h_qJjzubDpIyCGu8PBmZ_PV65dLlzkS
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import yfinance as yf
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

nifty = yf.Ticker("^NSEI")

nifty_historical = nifty.history(period='max')

nifty_historical.head()

nifty_historical = nifty_historical.drop(['Dividends', 'Stock Splits'], axis=1)
nifty_historical.index = nifty_historical.index.strftime('%Y-%m-%d')
nifty_historical['Next_Close'] = nifty_historical['Close'].shift(-1)

nifty_historical.head()

nifty_close = nifty_historical['Close'].values

training_data_len = int(np.ceil( len(nifty_close) * .95 ))

training_data_len

scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(nifty_close.reshape(-1, 1))

X_train = []
y_train = []

for i in range(60, training_data_len):
  X_train.append(scaled_data[i-60:i, 0])
  y_train.append(scaled_data[i, 0])

X_train, y_train = np.array(X_train), np.array(y_train)
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))

def model_training_pred(model, X_train, y_train, training_data_len, scaled_data, scaler, nifty_close):
  early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)
  history = model.fit(X_train, y_train, epochs=100, batch_size=32, callbacks=[early_stop])

  test_data = scaled_data[training_data_len - 60 :, :]
  X_test = []
  y_test = nifty_close[training_data_len:]

  for i in range(60, len(test_data)):
      X_test.append(test_data[i-60:i, 0])

  X_test = np.array(X_test)
  X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

  predictions = model.predict(X_test)
  predictions = scaler.inverse_transform(predictions)

  rmse = np.sqrt(np.mean(((predictions - y_test) ** 2)))

  plt.clf()
  plt.figure(figsize=(14, 5))
  plt.plot(y_test, color='red', label='Real Nifty 50 Stock Price')
  plt.plot(predictions, color='blue', label='Predicted Nifty 50 Stock Price')
  plt.title('Nifty 50 Price Prediction')
  plt.xlabel('Time')
  plt.ylabel('Nifty 50 Price')
  plt.legend()
  plt.show()

  results = pd.DataFrame({
    'Actual': y_test,
    'Predicted': predictions.flatten()
  })

  results['Diff'] = (results['Actual'] - results['Predicted']) / results['Actual'] * 100
  return history, rmse, results

model1 = Sequential()

model1.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))
model1.add(Dropout(0.2))
model1.add(LSTM(units=50, return_sequences=True))
model1.add(Dropout(0.2))
model1.add(LSTM(units=50))
model1.add(Dropout(0.2))
model1.add(Dense(units=1))

model1.compile(optimizer='adam', loss='mean_squared_error')
model1_output = model_training_pred(model1, X_train, y_train, training_data_len, scaled_data, scaler, nifty_close)

model2 = Sequential()

model2.add(LSTM(128, return_sequences=True, input_shape= (X_train.shape[1], 1)))
model2.add(LSTM(64, return_sequences=False))
model2.add(Dense(25))
model2.add(Dense(1))

model2.compile(optimizer='adam', loss='mean_squared_error')
model2_output = model_training_pred(model2, X_train, y_train, training_data_len, scaled_data, scaler, nifty_close)

model3 = Sequential()

model3.add(LSTM(128, return_sequences=True, input_shape= (X_train.shape[1], 1)))
model3.add(Dropout(0.2))
model3.add(LSTM(64, return_sequences=False))
model3.add(Dense(32))
model3.add(Dense(1))

model3.compile(optimizer='adam', loss='mean_squared_error')
model3_output = model_training_pred(model3, X_train, y_train, training_data_len, scaled_data, scaler, nifty_close)

model4 = Sequential()

model4.add(LSTM(128, return_sequences=True, input_shape= (X_train.shape[1], 1)))
model4.add(Dropout(0.2))
model4.add(LSTM(128, return_sequences=True, input_shape= (X_train.shape[1], 1)))
model4.add(Dropout(0.1))
model4.add(LSTM(64, return_sequences=False))
model4.add(Dense(32))
model4.add(Dense(1))

model4.compile(optimizer='adam', loss='mean_squared_error')
model4_output = model_training_pred(model4, X_train, y_train, training_data_len, scaled_data, scaler, nifty_close)

model5 = Sequential()

model5.add(LSTM(128, return_sequences=True, input_shape= (X_train.shape[1], 1)))
model5.add(Dropout(0.2))
model5.add(LSTM(128, return_sequences=True, input_shape= (X_train.shape[1], 1)))
model5.add(Dropout(0.1))
model5.add(LSTM(64, return_sequences=False))
model5.add(Dense(1))

model5.compile(optimizer='adam', loss='mean_squared_error')
model5_output = model_training_pred(model5, X_train, y_train, training_data_len, scaled_data, scaler, nifty_close)

model6 = Sequential()

model6.add(LSTM(128, return_sequences=True, input_shape= (X_train.shape[1], 1)))
model6.add(Dropout(0.2))
model6.add(LSTM(128, return_sequences=True, input_shape= (X_train.shape[1], 1)))
model6.add(Dropout(0.1))
model6.add(LSTM(64, return_sequences=False))
model6.add(Dense(1))

model6.compile(optimizer='adam', loss='mean_squared_error')

early_stop = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)
history = model6.fit(X_train, y_train, epochs=10, batch_size=32, callbacks=[early_stop])

test_data = scaled_data[training_data_len - 60 :, :]
X_test = []
y_test = nifty_close[training_data_len:]

for i in range(60, len(test_data)):
    X_test.append(test_data[i-60:i, 0])

X_test = np.array(X_test)
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

predictions = model6.predict(X_test)
predictions = scaler.inverse_transform(predictions)

rmse = np.sqrt(np.mean(((predictions - y_test) ** 2)))

plt.clf()
plt.figure(figsize=(14, 5))
plt.plot(y_test, color='red', label='Real Nifty 50 Stock Price')
plt.plot(predictions, color='blue', label='Predicted Nifty 50 Stock Price')
plt.title('Nifty 50 Price Prediction')
plt.xlabel('Time')
plt.ylabel('Nifty 50 Price')
plt.legend()
plt.show()

results = pd.DataFrame({
  'Actual': y_test,
  'Predicted': predictions.flatten()
})

results['Diff'] = (results['Actual'] - results['Predicted']) / results['Actual'] * 100
model6_output = history, rmse, results

model7 = Sequential()

model7.add(LSTM(128, return_sequences=True, input_shape= (X_train.shape[1], 1)))
model7.add(Dropout(0.2))
model7.add(LSTM(128, return_sequences=True, input_shape= (X_train.shape[1], 1)))
model7.add(Dropout(0.3))
model7.add(LSTM(64, return_sequences=False))
model7.add(Dense(1))

model7.compile(optimizer='adam', loss='mean_squared_error')

early_stop = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)
history = model7.fit(X_train, y_train, epochs=10, batch_size=32, callbacks=[early_stop])

test_data = scaled_data[training_data_len - 60 :, :]
X_test = []
y_test = nifty_close[training_data_len:]

for i in range(60, len(test_data)):
    X_test.append(test_data[i-60:i, 0])

X_test = np.array(X_test)
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

predictions = model7.predict(X_test)
predictions = scaler.inverse_transform(predictions)

rmse = np.sqrt(np.mean(((predictions - y_test) ** 2)))

plt.clf()
plt.figure(figsize=(14, 5))
plt.plot(y_test, color='red', label='Real Nifty 50 Stock Price')
plt.plot(predictions, color='blue', label='Predicted Nifty 50 Stock Price')
plt.title('Nifty 50 Price Prediction')
plt.xlabel('Time')
plt.ylabel('Nifty 50 Price')
plt.legend()
plt.show()

results = pd.DataFrame({
  'Actual': y_test,
  'Predicted': predictions.flatten()
})

results['Diff'] = (results['Actual'] - results['Predicted']) / results['Actual'] * 100
model7_output = history, rmse, results

print("Model 1 RMSE: ",model1_output[1])
print("Model 2 RMSE: ",model2_output[1])
print("Model 3 RMSE: ",model3_output[1])
print("Model 4 RMSE: ",model4_output[1])
print("Model 5 RMSE: ",model5_output[1])
print("Model 6 RMSE: ",model6_output[1])
print("Model 7 RMSE: ",model7_output[1])

print("Model 1 RMSE: ",model1_output[0].history['loss'][-1])
print("Model 2 RMSE: ",model2_output[0].history['loss'][-1])
print("Model 3 RMSE: ",model3_output[0].history['loss'][-1])
print("Model 4 RMSE: ",model4_output[0].history['loss'][-1])
print("Model 5 RMSE: ",model5_output[0].history['loss'][-1])
print("Model 6 RMSE: ",model6_output[0].history['loss'][-1])
print("Model 7 RMSE: ",model7_output[0].history['loss'][-1])

print("Model 1:", model1_output[2].Diff.min(), model1_output[2].Diff.mean(), model1_output[2].Diff.max())
print("Model 2:", model2_output[2].Diff.min(), model2_output[2].Diff.mean(), model2_output[2].Diff.max())
print("Model 3:", model3_output[2].Diff.min(), model3_output[2].Diff.mean(), model3_output[2].Diff.max())
print("Model 4:", model4_output[2].Diff.min(), model4_output[2].Diff.mean(), model4_output[2].Diff.max())
print("Model 5:", model5_output[2].Diff.min(), model5_output[2].Diff.mean(), model5_output[2].Diff.max())
print("Model 6:", model6_output[2].Diff.min(), model6_output[2].Diff.mean(), model6_output[2].Diff.max())
print("Model 7:", model7_output[2].Diff.min(), model7_output[2].Diff.mean(), model7_output[2].Diff.max())

model5_output[2]









import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras import layers
from tensorflow.keras.callbacks import EarlyStopping

df = pd.read_csv("nifty.csv")

df

df = df[['Date', 'Close']]

df.loc[:, 'Date'] = pd.to_datetime(df['Date'])

df.set_index('Date', inplace=True)

df.fillna(method='ffill', inplace=True)

plt.plot(df.index, df['Close'])

df_close = df['Close'].values

training_data_len = int(np.ceil( len(df_close) * .8 ))
val_data_len = int(np.ceil(len(df_close) * .9))

scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(df_close.reshape(-1, 1))

dates_train = []
dates_val = []
dates_test = []
X_train = []
X_val = []
X_test = []
y_train = []
y_val = []
y_test = []

for i in range(60, training_data_len):
  dates_train.append(df.index.values[i])
  X_train.append(scaled_data[i-60:i, 0])
  y_train.append(scaled_data[i, 0])

X_train, y_train = np.array(X_train), np.array(y_train)
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))


for i in range(training_data_len, val_data_len):
  dates_val.append(df.index.values[i])
  X_val.append(scaled_data[i-60:i, 0])
  y_val.append(scaled_data[i, 0])

X_val, y_val = np.array(X_val), np.array(y_val)
X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))

for i in range(val_data_len, len(scaled_data)):
  dates_test.append(df.index.values[i])
  X_test.append(scaled_data[i-60:i, 0])
  y_test.append(scaled_data[i, 0])

X_test, y_test = np.array(X_test), np.array(y_test)
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

plt.plot(dates_train, y_train)
plt.plot(dates_val, y_val)
plt.plot(dates_test, y_test)
plt.legend(['Train', 'Validation', 'Test'])

X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape

def prediction(model, dates_train, X_train, y_train, dates_val, X_val, y_val, dates_test, X_test, y_test):
  train_predictions = model.predict(X_train).flatten()
  val_predictions = model.predict(X_val).flatten()
  test_predictions = model.predict(X_test).flatten()

  plt.plot(dates_train, train_predictions)
  plt.plot(dates_train, y_train)
  plt.plot(dates_val, val_predictions)
  plt.plot(dates_val, y_val)
  plt.plot(dates_test, test_predictions)
  plt.plot(dates_test, y_test)

  plt.legend(['Train Predictions', 'Train Observations', 'Val Predictions', 'Val Observations', 'Test Predictions', 'Test Observations'])

  return train_predictions, val_predictions, test_predictions

model1 = Sequential([layers.Input((60, 1)),
                     layers.LSTM(64),
                     layers.Dense(32, activation='relu'),
                     layers.Dense(32, activation='relu'),
                     layers.Dense(1)])

model1.compile(loss='mse', optimizer=Adam(learning_rate=0.001), metrics=['mean_absolute_error'])

early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)
history = model1.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, callbacks=[early_stop])

model1_preds = prediction(model1, dates_train, X_train, y_train, dates_val, X_val, y_val, dates_test, X_test, y_test)

rmse_train = np.sqrt(np.mean(((model1_preds[0] - y_train) ** 2)))
rmse_val = np.sqrt(np.mean(((model1_preds[1] - y_val) ** 2)))
rmse_test = np.sqrt(np.mean(((model1_preds[2] - y_test) ** 2)))

rmse_train, rmse_val, rmse_test



model2 = Sequential([layers.Input((60, 1)),
                     layers.LSTM(64),
                     layers.Dropout(0.2),
                     layers.Dense(32),
                     layers.Dense(1)])

model2.compile(loss='mse', optimizer=Adam(learning_rate=0.001), metrics=['mean_absolute_error'])

early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)
model2_history = model2.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, callbacks=[early_stop])

model2_preds = prediction(model2, dates_train, X_train, y_train, dates_val, X_val, y_val, dates_test, X_test, y_test)

rmse_train = np.sqrt(np.mean(((model2_preds[0] - y_train) ** 2)))
rmse_val = np.sqrt(np.mean(((model2_preds[1] - y_val) ** 2)))
rmse_test = np.sqrt(np.mean(((model2_preds[2] - y_test) ** 2)))

rmse_train, rmse_val, rmse_test



model3 = Sequential([layers.Input((60, 1)),
                     layers.LSTM(64),
                     layers.Dense(32, activation='relu'),
                     layers.Dense(32, activation='relu'),
                     layers.Dense(1)])

model3.compile(loss='mse', optimizer=Adam(learning_rate=0.0001), metrics=['mean_absolute_error'])

early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)
model3_history = model3.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, callbacks=[early_stop])

model3_preds = prediction(model3, dates_train, X_train, y_train, dates_val, X_val, y_val, dates_test, X_test, y_test)

rmse_train = np.sqrt(np.mean(((model3_preds[0] - y_train) ** 2)))
rmse_val = np.sqrt(np.mean(((model3_preds[1] - y_val) ** 2)))
rmse_test = np.sqrt(np.mean(((model3_preds[2] - y_test) ** 2)))

rmse_train, rmse_val, rmse_test

model4 = Sequential([
    layers.Input((60, 1)),
    layers.LSTM(128, return_sequences=True),
    Dropout(0.2),
    layers.LSTM(64),
    Dropout(0.2),
    layers.Dense(32, activation='relu'),
    Dropout(0.2),
    layers.Dense(1)
])

model4.compile(loss='mse', optimizer=Adam(learning_rate=0.0001), metrics=['mean_absolute_error'])

early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)
model4_history = model4.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, callbacks=[early_stop])

model4_preds = prediction(model4, dates_train, X_train, y_train, dates_val, X_val, y_val, dates_test, X_test, y_test)

rmse_train = np.sqrt(np.mean(((model4_preds[0] - y_train) ** 2)))
rmse_val = np.sqrt(np.mean(((model4_preds[1] - y_val) ** 2)))
rmse_test = np.sqrt(np.mean(((model4_preds[2] - y_test) ** 2)))

rmse_train, rmse_val, rmse_test



model5 = Sequential([layers.Input((60, 1)),
                     layers.LSTM(64),
                     layers.Dense(32, activation='relu'),
                     layers.Dense(32, activation='relu'),
                     layers.Dense(1)])

model5.compile(loss='mse', optimizer=Adam(learning_rate=0.0005), metrics=['mean_absolute_error'])

early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)
model5_history = model5.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, callbacks=[early_stop])

model5_preds = prediction(model5, dates_train, X_train, y_train, dates_val, X_val, y_val, dates_test, X_test, y_test)

rmse_train = np.sqrt(np.mean(((model5_preds[0] - y_train) ** 2)))
rmse_val = np.sqrt(np.mean(((model5_preds[1] - y_val) ** 2)))
rmse_test = np.sqrt(np.mean(((model5_preds[2] - y_test) ** 2)))

rmse_train, rmse_val, rmse_test



model6 = Sequential([
    layers.Input((60, 1)),  # Input shape: (timesteps, features)
    layers.LSTM(128, return_sequences=True),  # Output shape: (batch_size, timesteps, units)
    layers.LSTM(64),  # Output shape: (batch_size, units)
    layers.Dense(32, activation='relu'),
    layers.Dense(1)
])

model6.compile(loss='mse', optimizer=Adam(learning_rate=0.001), metrics=['mean_absolute_error'])

early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)
model6_history = model6.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, callbacks=[early_stop])

model6_preds = prediction(model6, dates_train, X_train, y_train, dates_val, X_val, y_val, dates_test, X_test, y_test)

rmse_train = np.sqrt(np.mean(((model6_preds[0] - y_train) ** 2)))
rmse_val = np.sqrt(np.mean(((model6_preds[1] - y_val) ** 2)))
rmse_test = np.sqrt(np.mean(((model6_preds[2] - y_test) ** 2)))

rmse_train, rmse_val, rmse_test

plt.plot(dates_val, model6_preds[1])
plt.plot(dates_val, y_val)
# plt.plot(dates_test, model6_preds[2])
# plt.plot(dates_test, y_test)

plt.legend(['Val Predictions', 'Val Observations', 'Test Predictions', 'Test Observations'])

model7 = Sequential([
    layers.Input((60, 1)),  # Input shape: (timesteps, features)
    layers.LSTM(128, return_sequences=True),  # Output shape: (batch_size, timesteps, units)
    layers.LSTM(128, return_sequences=True),  # Output shape: (batch_size, timesteps, units)
    layers.Dense(32, activation='relu'),
    layers.LSTM(64),  # Output shape: (batch_size, units)
    layers.Dense(32, activation='relu'),
    layers.Dense(1)
])

model7.compile(loss='mse', optimizer=Adam(learning_rate=0.001), metrics=['mean_absolute_error'])

early_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)
model7_history = model7.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, callbacks=[early_stop])

model7_preds = prediction(model7, dates_train, X_train, y_train, dates_val, X_val, y_val, dates_test, X_test, y_test)

rmse_train = np.sqrt(np.mean(((model7_preds[0] - y_train) ** 2)))
rmse_val = np.sqrt(np.mean(((model7_preds[1] - y_val) ** 2)))
rmse_test = np.sqrt(np.mean(((model7_preds[2] - y_test) ** 2)))

rmse_train, rmse_val, rmse_test



(0.005314863638832331, 0.010983309016109022, 0.010618368091226594)
(0.0045111471538190825, 0.008867011019022899, 0.00832532719125168)

# rmse_train = np.sqrt(np.mean(((model6_preds[0] - y_train) ** 2)))
# rmse_val = np.sqrt(np.mean(((model6_preds[1] - y_val) ** 2)))
# rmse_test = np.sqrt(np.mean(((model6_preds[2] - y_test) ** 2)))

# rmse_train, rmse_val, rmse_test

model6s_preds = scaler.inverse_transform(np.array(model6_preds[2]).reshape(-1, 1))
y_test_normal = scaler.inverse_transform(np.array(y_test).reshape(-1, 1))
diff_normal = model6s_preds - y_test_normal

model_pred_df = pd.DataFrame(data={
    'Test Data': y_test_normal.flatten(),
    'Model Preds': model6s_preds.flatten(),
    'Difference': diff_normal.flatten(),
})

model_pred_df['Difference'].max()

model_pred_df['Difference'].min()

model_pred_df['Difference'].describe()

start_range = 0
end_range = len(model_pred_df)

mean_diff = model_pred_df['Difference'][start_range:end_range].mean()
std_dev_diff  = model_pred_df['Difference'][start_range:end_range].std()

fig, ax1 = plt.subplots(figsize=(12, 6))

# Plot the actual test data and model predictions
ax1.plot(dates_test[start_range:end_range], model_pred_df['Test Data'][start_range:end_range], label='Test Data', color='blue')
ax1.plot(dates_test[start_range:end_range], model_pred_df['Model Preds'][start_range:end_range], label='Model Prediction', color='orange')
ax1.set_xlabel('Date')
ax1.set_ylabel('Close Price')
ax1.set_title('Model Prediction vs Test Data')
ax1.legend(loc='upper left')

# Create a secondary y-axis to plot the differences
ax2 = ax1.twinx()
ax2.bar(dates_test[start_range:end_range], model_pred_df['Difference'][start_range:end_range], alpha=0.4, color='red', label='Difference')
ax2.set_ylim(-1000, 1000)
ax2.set_ylabel('Difference')

ax2.axhline(y=mean_diff, color='green', linestyle='--', linewidth=2, label='Mean Difference')
ax2.annotate(f'Mean Difference: {mean_diff:.5f}', xy=(dates_test[start_range], mean_diff), xytext=(dates_test[start_range], mean_diff + 15),
             arrowprops=dict(facecolor='black', shrink=0.05), fontsize=12, color='black')

ax2.axhline(y=mean_diff + std_dev_diff, color='purple', linestyle='--', linewidth=2, label='Mean + 1 Std Dev')
ax2.axhline(y=mean_diff - std_dev_diff, color='purple', linestyle='--', linewidth=2, label='Mean - 1 Std Dev')
ax2.annotate(f'Mean + 1 Std Dev: {mean_diff + std_dev_diff:.5f}', xy=(dates_test[start_range], mean_diff + std_dev_diff), xytext=(dates_test[start_range], mean_diff + std_dev_diff + 10),
             arrowprops=dict(facecolor='black', shrink=0.05), fontsize=12, color='purple')
ax2.annotate(f'Mean - 1 Std Dev: {mean_diff - std_dev_diff:.5f}', xy=(dates_test[start_range], mean_diff - std_dev_diff), xytext=(dates_test[start_range], mean_diff - std_dev_diff + 10),
             arrowprops=dict(facecolor='black', shrink=0.05), fontsize=12, color='purple')


ax2.legend(loc='lower right')

plt.show()

import joblib

# Save the model
model6.save('model6.h5')

# Save the scaler
joblib.dump(scaler, 'scaler.pkl')

from tensorflow.keras.models import load_model
import joblib

# Load the model
loaded_model = load_model('model6.h5')

# Load the scaler
loaded_scaler = joblib.load('scaler.pkl')

def predict_next_price(model, scaler, new_data, sequence_length=60):
    # Ensure the new data is a numpy array
    new_data = np.array(new_data).reshape(-1, 1)

    # Scale the new data using the same scaler used during training
    scaled_new_data = scaler.transform(new_data)

    # Prepare the input sequence
    input_sequence = scaled_new_data[-sequence_length:].reshape(1, sequence_length, 1)  # Shape should be (1, sequence_length, 1)

    # Predict the next value
    predicted_scaled_value = model.predict(input_sequence)

    # Denormalize the predicted value
    predicted_value = scaler.inverse_transform(predicted_scaled_value)[0][0]

    return predicted_value

# Example usage with new data
import yfinance as yf

nifty = yf.Ticker("^NSEI")

df = nifty.history(period='max')

new_data = df['Close'][-60:].values

next_price = predict_next_price(loaded_model, loaded_scaler, new_data)
print(f"Predicted next close price: {next_price}")

